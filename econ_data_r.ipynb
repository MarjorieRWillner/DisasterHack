{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db419635-9e2a-4ed0-91d5-01e0b5eb3a6d",
   "metadata": {},
   "source": [
    "# Connecting to econ data in Sagemaker Studio Lab with R \n",
    "\n",
    "[![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/MarjorieRWillner/DisasterHack/blob/main/econ_data_extract_r.ipynb)\n",
    "\n",
    "## FRED data\n",
    "\n",
    "Short for Federal Reserve Economic Data, FRED is an online database consisting of hundreds of thousands of economic data time series from scores of national, international, public, and private sources. FRED, created and maintained by the Research Department at the Federal Reserve Bank of St. Louis, goes far beyond simply providing data: It combines data with a powerful mix of tools that help the user understand, interact with, display, and disseminate the data. In essence, FRED helps users tell their data stories. The purpose of this article is to guide the potential (or current) FRED user through the various aspects and tools of the database.\n",
    "\n",
    "This is likely the easiest way to get data from U.S. statistical agencies like the Census and the BLS. In order to get this code to work you must obtain an api key from FRED: https://fredaccount.stlouisfed.org/apikeys\n",
    "\n",
    "We will be using the fredr package: https://sboysel.github.io/fredr/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35d9dcab-fad1-4ac8-afa0-2aeb66317de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 102\n",
      "Columns: 5\n",
      "$ date           \u001b[3m\u001b[90m<date>\u001b[39m\u001b[23m 2020-01-01, 2021-01-01, 2020-01-01, 2021-01-01, 2020-0…\n",
      "$ series_id      \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"ALPOP\", \"ALPOP\", \"AKPOP\", \"AKPOP\", \"AZPOP\", \"AZPOP\", \"…\n",
      "$ value          \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 5024.803, 5039.877, 732.441, 732.673, 7177.986, 7276.31…\n",
      "$ realtime_start \u001b[3m\u001b[90m<date>\u001b[39m\u001b[23m 2022-01-21, 2022-01-21, 2022-01-21, 2022-01-21, 2022-0…\n",
      "$ realtime_end   \u001b[3m\u001b[90m<date>\u001b[39m\u001b[23m 2022-01-21, 2022-01-21, 2022-01-21, 2022-01-21, 2022-0…\n"
     ]
    }
   ],
   "source": [
    "# This code will gather the population of each US state over time\n",
    "\n",
    "# install.packages(\"fredr\")\n",
    "# install.packages(\"tidyverse\")\n",
    "suppressWarnings(suppressMessages(library(fredr)))\n",
    "suppressWarnings(suppressMessages(library(tidyverse)))\n",
    "\n",
    "# your api key goes here\n",
    "fredr_set_key(\"\")\n",
    "\n",
    "# the fredr series id we want is DCPOP, FLPOP, VAPOP, MDPOP, etc. We will create\n",
    "# a list with all the states in the format of [ST]POP.\n",
    "state_id <- c(map_chr(state.abb, ~ paste0(.x, \"POP\")), \"DCPOP\")\n",
    "\n",
    "# We can now map over state_id and get the population for each state using the\n",
    "# fredr() function\n",
    "state_df <- map_dfr(\n",
    "  state_id,\n",
    "  ~ fredr(\n",
    "    series_id = .x, \n",
    "    observation_start = as.Date(\"2020-01-01\"), \n",
    "    observation_end = as.Date(\"2021-01-01\")\n",
    "    )\n",
    "  )\n",
    "\n",
    "glimpse(state_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979e953b-b716-471f-bc7b-8a8342e5b718",
   "metadata": {},
   "source": [
    "***\n",
    "## Census data\n",
    "\n",
    "Connect to Census via the tidycensus package - tidycensus is an R package that allows users to interface with a select number of the US Census Bureau’s data APIs and return tidyverse-ready data frames, optionally with simple feature geometry included.\n",
    "\n",
    "Accessing the Census directly allows for retrievel of ACS microdata files so that we can combine in a way that makes sense for our project. To get started working with tidycensus, users should load the package along with the tidyverse package, and set their Census API key. A key can be obtained from http://api.census.gov/data/key_signup.html.\n",
    "\n",
    "NOTE: To install tidycensus in sagemake you need to run the following code in the terminal \n",
    "\n",
    "    conda install -n R -c conda-forge r-tidycensus\n",
    "\n",
    "Reference: https://aws.amazon.com/blogs/machine-learning/creating-a-persistent-custom-r-environment-for-amazon-sagemaker/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317da57a-1917-4235-b6bb-875074f6b0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can run terminal commands in r via the system() function as shown here.\n",
    "system(command = 'conda install -c r tidycensus --yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505e3abf-bdae-4ba3-8d91-2770b2b18ffc",
   "metadata": {},
   "source": [
    "***\n",
    "get_pums() returns some technical variables by default without the user needing to request them specifically. These include:\n",
    "\n",
    "- SERIALNO: a serial number that uniquely identifies households in the sample;\n",
    "- SPORDER: the order of the person in the household; when combined with SERIALNO, uniquely identifies a person;\n",
    "- WGTP: the household weight;\n",
    "- PWGTP: the person weight\n",
    "- PUMA: Public Use Microdata Areas (PUMAs) are the smallest available geographies at which records are identifiable in the PUMS datasets. PUMAs are redrawn with each decennial US Census, and typically are home to 100,000-200,000 people. In large cities, a PUMA will represent a collection of nearby neighborhoods; in rural areas, it might represent several counties across a large area of a state.\n",
    "\n",
    "It is a long-form dataset that organizes specific value codes by variable so you know what you can get. You'll use information in the var_code column to fetch variables, but pay attention to the var_label, val_code, val_label, and data_type columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b97dd6bc-2cc2-4e8b-99eb-93b62b096173",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To install your API key for use in future sessions, run this function with `install = TRUE`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 5,277\n",
      "Columns: 12\n",
      "$ survey     \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"acs5\", \"acs5\", \"acs5\", \"acs5\", \"acs5\", \"acs5\", \"acs5\", \"ac…\n",
      "$ year       \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"2019\", \"2019\", \"2019\", \"2019\", \"2019\", \"2019\", \"2019\", \"20…\n",
      "$ var_code   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"ENG\", \"ENG\", \"ENG\", \"ENG\", \"ENG\", \"FENGP\", \"FENGP\", \"ACCES…\n",
      "$ var_label  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"Ability to speak English\", \"Ability to speak English\", \"Ab…\n",
      "$ data_type  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"chr\", \"chr\", \"chr\", \"chr\", \"chr\", \"chr\", \"chr\", \"chr\", \"ch…\n",
      "$ level      \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"person\", \"person\", \"person\", \"person\", \"person\", \"person\",…\n",
      "$ val_min    \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"b\", \"1\", \"2\", \"3\", \"4\", \"0\", \"1\", \"b\", \"1\", \"2\", \"3\", \"b\",…\n",
      "$ val_max    \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"b\", \"1\", \"2\", \"3\", \"4\", \"0\", \"1\", \"b\", \"1\", \"2\", \"3\", \"b\",…\n",
      "$ val_label  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"N/A (less than 5 years old/speaks only English)\", \"Very we…\n",
      "$ recode     \u001b[3m\u001b[90m<lgl>\u001b[39m\u001b[23m TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE,…\n",
      "$ val_length \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 7, 7, 7, 7, 7,…\n",
      "$ val_na     \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0, 0, 0, 0, 0, NA, NA, 0, 0, 0, 0, -1, -1, -1, NA, NA, NA, …\n"
     ]
    }
   ],
   "source": [
    "suppressWarnings(suppressMessages(library(\"tidycensus\")))\n",
    "suppressWarnings(suppressMessages(library(\"tidyverse\")))\n",
    "\n",
    "# your api key goes here\n",
    "census_api_key(\"\", overwrite = TRUE, install = FALSE)\n",
    "\n",
    "# we can get a list of all the variables that are available to us to choose from\n",
    "pums_var <- pums_variables %>%\n",
    "  filter(year == 2019, survey == \"acs5\") %>%\n",
    "  arrange(var_label) \n",
    "\n",
    "# we now have a table with all the variables available to us\n",
    "glimpse(pums_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8efad61-47d0-4e22-925b-aaafd5afe819",
   "metadata": {},
   "source": [
    "There are *more than 500* variables to choose from. Please reference the PUMS data dictionary located here: https://www2.census.gov/programs-surveys/acs/tech_docs/pums/data_dict/. \n",
    "\n",
    "The most recent 5 year ACS data dictionary is here: https://www2.census.gov/programs-surveys/acs/tech_docs/pums/data_dict/PUMS_Data_Dictionary_2015-2019.pdf \n",
    "\n",
    "The most recent 1 year ACS data dictionary is here: https://www2.census.gov/programs-surveys/acs/tech_docs/pums/data_dict/PUMS_Data_Dictionary_2019.pdf\n",
    "\n",
    "Once you know what you want you can use the get_pums() function to bring in all the microdata. \n",
    "\n",
    "**WARNING** Be careful here, Census ACS microdata is huge and can take a long time to retrieve if the request is not targetted well enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175724da-afaa-4981-9efa-24717f84c5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting data from the 2015-2019 5-year ACS Public Use Microdata Sample\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 480 MB     "
     ]
    }
   ],
   "source": [
    "# retrieve 5 year ACS microdata for CA. This is 480 MB and takes a few minutes to download.\n",
    "state_pums <- get_pums(\n",
    "  variables = c(\n",
    "    \"ACCESS\", \"ADJINC\", \"AGEP\", \"CIT\", \"CITWP\", \"DECADE\", \"ELEP\", \"ENG\", \"FINCP\", \"GASP\", \"GRNTP\", \"GRPIP\", \"HHT\", \"HINCP\", \"HISPEED\", \"MIGSP\", \"MRGP\", \n",
    "      \"MV\",  \"NAICSP\", \"NATIVITY\", \"NOP\", \"NPF\", \"OCPIP\", \"OCCP\", \"PINCP\", \"PERNP\", \"POBP\", \"POVPIP\", \"PUMA\", \"REGION\", \"RNTP\", \"SCHL\", \"SEX\", \"ST\",\n",
    "      \"TAXAMT\", \"TEN\", \"WAGP\", \"WATP\", \"WGTP\", \"YOEP\", \"ACR\", \"NP\", \"BLD\"\n",
    "  ),\n",
    "  state = \"CA\",\n",
    "  survey = \"acs5\",\n",
    "  recode = TRUE\n",
    ")\n",
    "\n",
    "glimpse(state_pums)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71520d1-44ed-4161-852d-0d47d504a802",
   "metadata": {},
   "source": [
    "***\n",
    "Some of this microdata pertains to person level data and household level data. We need to split the data into these 2 categories and then apply adjustment factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3b7e68a-6052-4140-8b50-9d4016ab70d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in state_pums %>% transmute(SERIALNO, NPF, WGTP, ADJHSG = as.numeric(ADJHSG), : could not find function \"%>%\"\n",
     "output_type": "error",
     "traceback": [
      "Error in state_pums %>% transmute(SERIALNO, NPF, WGTP, ADJHSG = as.numeric(ADJHSG), : could not find function \"%>%\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "# lets address the householf variables first\n",
    "state_pums_hh <- state_pums %>%\n",
    "    transmute(\n",
    "        SERIALNO,\n",
    "        NPF,\n",
    "        WGTP,\n",
    "        ADJHSG = as.numeric(ADJHSG),\n",
    "        ADJINC = as.numeric(ADJINC),\n",
    "        PUMA,\n",
    "        ST,\n",
    "        ST_label,\n",
    "        ACCESS,\n",
    "        ACCESS_label,\n",
    "        ACR,\n",
    "        ACR_label,\n",
    "        BLD,\n",
    "        BLD_label,\n",
    "        ELEP = as.numeric(ELEP) * ADJHSG,\n",
    "        FINCP = as.numeric(FINCP) * ADJINC,\n",
    "        GASP = as.numeric(GASP) * ADJHSG,\n",
    "        GRPIP,\n",
    "        GRNTP = as.numeric(GRNTP) * ADJHSG,\n",
    "        HHT,\n",
    "        HHT_label,\n",
    "        HINCP = as.numeric(HINCP) * ADJINC,\n",
    "        HISPEED,\n",
    "        HISPEED_label,\n",
    "        MRGP = as.numeric(MRGP) * ADJHSG,\n",
    "        MV,\n",
    "        MV_label,\n",
    "        NP,\n",
    "        OCPIP,\n",
    "        RNTP = as.numeric(RNTP) * ADJHSG,\n",
    "        TAXAMT = as.numeric(TAXAMT) * ADJHSG,\n",
    "        TEN,\n",
    "        TEN_label,\n",
    "        WATP = as.numeric(WATP) * ADJHSG\n",
    "    ) %>%\n",
    "    distinct()\n",
    "\n",
    "# next we'll do person level data but first lets get a list of all the household level variables\n",
    "state_pums_hh_colnames <- colnames(state_pums_hh)\n",
    "\n",
    "# create person level data\n",
    "state_pums_p <- state_pums %>%\n",
    "    # remove the household level variables\n",
    "    select(-one_of(state_pums_hh_colnames)) %>%\n",
    "    # bring back in the weights and id variables\n",
    "    bind_cols(\n",
    "        state_pums %>%\n",
    "            transmute(\n",
    "                SERIALNO,\n",
    "                NPF,\n",
    "                ADJHSG = as.numeric(ADJHSG),\n",
    "                ADJINC = as.numeric(ADJINC),\n",
    "                PUMA,\n",
    "                ST,\n",
    "                ST_label\n",
    "            )\n",
    "    ) %>%\n",
    "    # keep the person level variables and make adjustments\n",
    "    transmute(\n",
    "        SERIALNO,\n",
    "        SPORDER,\n",
    "        PWGTP,\n",
    "        ADJHSG = ADJHSG/1000000,\n",
    "        ADJINC = ADJINC/1000000,\n",
    "        PUMA,\n",
    "        ST,\n",
    "        ST_label,\n",
    "        AGEP,\n",
    "        CIT,\n",
    "        CIT_label,\n",
    "        CITWP = lubridate::ymd(CITWP, truncated = 2L),\n",
    "        DECADE,\n",
    "        DECADE_label,\n",
    "        ENG,\n",
    "        ENG_label,\n",
    "        MIGSP,\n",
    "        MIGSP_label,\n",
    "        NAICSP,\n",
    "        NAICSP_label,\n",
    "        NATIVITY,\n",
    "        NATIVITY_label,\n",
    "        NOP,\n",
    "        NOP_label,\n",
    "        OCCP,\n",
    "        OCCP_label,\n",
    "        PERNP = as.numeric(PERNP) * ADJINC,\n",
    "        PINCP = as.numeric(PINCP) * ADJINC,\n",
    "        POBP,\n",
    "        POBP_label,\n",
    "        POVPIP,\n",
    "        SCHL,\n",
    "        SCHL_label,\n",
    "        SEX,\n",
    "        SEX_label,\n",
    "        WAGP = as.numeric(WAGP) * ADJINC,\n",
    "        YOEP = lubridate::ymd(CITWP, truncated = 2L)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd015a6f-5b85-4d67-9a37-8fffbbc5054a",
   "metadata": {},
   "source": [
    "With this cleaned up data we can start getting counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b700dcd7-c997-4513-9405-b0fb1fce2bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get population counts by building units in structure\n",
    "state_pums_hh %>%\n",
    "    group_by(PUMA) %>%\n",
    "    mutate(\n",
    "        tot_pop = sum(WGTP)\n",
    "    ) %>%\n",
    "    group_by(PUMA, tot_pop, BLD_label) %>%\n",
    "    summarize(\n",
    "        BLD_tot_pop = sum(WGTP),\n",
    "        BLD_per = round(BLD_tot_pop/tot_pop, 2)\n",
    "    ) %>%\n",
    "    distinct()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R:R",
   "language": "R",
   "name": "conda-env-R-r"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
